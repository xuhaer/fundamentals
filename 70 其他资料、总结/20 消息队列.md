# 消息队列

消息队列，一般我们会简称它为MQ(Message Queue)。消息队列可以简单理解为：**把要传输的数据放在队列中**。

**消息队列的主要特点是异步处理，主要目的是减少请求响应时间和解耦。**所以**主要的使用场景就是将比较耗时而且不需要即时(同步)返回结果的操作作为消息放入消息队列**。同时由于使用了消息队列，只要保证消息格式不变，消息的发送方和接收方并不需要彼此联系，也不需要受对方的影响，即解耦和。

使用场景的话，举个例子：
假设用户在你的软件中注册，服务端收到用户的注册请求后，它会做这些操作：

- 校验用户名等信息，如果没问题会在数据库中添加一个用户记录
- 如果是用邮箱注册会给你发送一封注册成功的邮件，手机注册则会发送一条短信
- 分析用户的个人信息，以便将来向他推荐一些志同道合的人，或向那些人推荐他
- 发送给用户一个包含操作指南的系统通知
- 等等……

但是对于用户来说，注册功能实际只需要第一步，只要服务端将他的账户信息存到数据库中他便可以登录上去做他想做的事情了。至于其他的事情，非要在这一次请求中全部完成么？值得用户浪费时间等你处理这些对他来说无关紧要的事情么？所以实际当第一步做完后，服务端就可以把其他的操作放入对应的消息队列中然后马上返回用户结果，由消息队列异步的进行这些操作。

或者还有一种情况，同时有大量用户注册你的软件，再高并发情况下注册请求开始出现一些问题，例如邮件接口承受不住，或是分析信息时的大量计算使cpu满载，这将会出现虽然用户数据记录很快的添加到数据库中了，但是却卡在发邮件或分析信息时的情况，导致请求的响应时间大幅增长，甚至出现超时，这就有点不划算了。面对这种情况一般也是将这些操作放入消息队列（生产者消费者模型），消息队列慢慢的进行处理，同时可以很快的完成注册请求，不会影响用户使用其他功能。

所以在软件的正常功能开发中，并不需要去刻意的寻找消息队列的使用场景，而是当出现性能瓶颈时，去查看业务逻辑是否存在可以异步处理的耗时操作，如果存在的话便可以引入消息队列来解决。否则盲目的使用消息队列可能会增加维护和开发的成本却无法得到可观的性能提升，那就得不偿失了。

## Celery

实现异步任务的工具有很多，其原理都是使用一个任务队列，其中一个例子就是Celery，它是一个由python编写的分布式任务队列，它可以让任务的执行完全脱离主程序，甚至可以被分配到其他主机上运行。我们通常使用它来实现异步任务（async task）和定时任务（crontab）。它的架构组成如下图：



![Celery_framework](./figure/celery.png)



可以看到，Celery 主要包含以下几个模块：

- 任务模块 Task

  包含异步任务和定时任务。其中，**异步任务通常在业务逻辑中被触发并发往任务队列，而定时任务由 Celery Beat 进程周期性地将任务发往任务队列**。

- 消息中间件 Broker

  Broker，即为任务调度队列，接收任务生产者发来的消息（即任务），将任务存入队列。**Celery 本身不提供队列服务，官方推荐使用 RabbitMQ 和 Redis 等。**

- 任务执行单元 Worker

  Worker 是执行任务的处理单元，**它实时监控消息队列，获取队列中调度的任务，并执行它**。

- 任务结果存储 Backend

  Backend 用于**存储任务的执行结果**，以供查询。同消息中间件一样，存储也可使用 RabbitMQ, Redis 和 MongoDB 等。
  
  

### 一个简单的使用事例(redis 的 docker 搭建见`12 docker.md`)：

首先，在`celery_demo`项目下创建一个 celery 实例(`task.py`)

然后，在项目路径下，启动 Celery Worker：

```bash
celery -A task worker --loglevel=info
# -A 指定了 Celery 实例的位置，本例是在 task.py 中，Celery 会自动在该文件中寻找 Celery 对象实例，当然，我们也可以自己指定，在本例，使用 -A task.app
# --loglevel 指定了日志级别，默认为 warning
```

启动成功后，可以看到一串串info 信息：如`[...... INFO/MainProcess] celery@Mac ready.`

现在，我们可以在另一个控制台中使用 `delay()` 或 `apply_async()` 方法来调用任务了：

```python
from task import add

add.delay(2, 8)
```

在上面，我们从 tasks.py 文件中导入了 add 任务对象，然后使用 delay() 方法, 将任务发送到消息中间件（Broker），Celery Worker 进程监控到该任务后，就会进行执行。我们将窗口切换到 Worker 的启动窗口，会看到多了两条日志：

```bash
INFO/MainProcess] Received task: task.add[xxxx] 
INFO/ForkPoolWorker-5] Task task.add[xxxx] succeeded in 5.0688639380000495s: 10
```

这说明任务已经被调度并执行成功。

当然，我们通常在应用程序中调用任务。比如，使用配置文件重新组织项目：

```bash
celery_demo                    # 项目根目录
    ├── celery_app             # 存放 celery 相关文件
    │   ├── __init__.py
    │   ├── celeryconfig.py    # 配置文件
    │   ├── add_task.py        # 任务文件 1
    │   └── multiply_res.py    # 任务文件 2
    └── main.py                # 应用程序
```

然后，同样先启动Celery Worker 进程，在项目的根目录下执行下面命令：

```bash
celery -A celery_app worker --loglevel=info
```

着，运行 `$ python main.py` 就可以使用 delay() 或 apply_async() 方法来调用任务了，它会发送两个异步任务到 Broker，在 Worker 的窗口我们可以看到有相应输出。

其实 delay 方法封装了 apply_async 而已，本质上并无区别。apply_async 有几个常用参数 ：
- countdown： 指定多少秒后执行任务
- eta (estimated time of arrival)：指定任务被调度的具体时间，参数类型是 datetime
- expires：任务过期时间，参数类型可以是 int，也可以是 datetime

此外，Celery 除了可以执行**异步任务**，也支持执行**周期性任务（Periodic Tasks）**，或者说定时任务。Celery Beat 进程通过读取配置文件的内容，周期性地将定时任务发往任务队列。

在celeryconfig.py 后面加上以下代码：

```python
# schedules
CELERYBEAT_SCHEDULE = {
    'add-every-30-seconds': {
         'task': 'celery_app.celery_app.add_task.add_task',
         'schedule': timedelta(seconds=30),       # 每 30 秒执行一次
         'args': (5, 8)                           # 任务函数参数
    },
    'multiply-at-some-time': {
        'task': 'celery_app.multiply_task.multiply_task',
        'schedule': crontab(hour=9, minute=50),   # 每天早上 9 点 50 分执行一次
        'args': (3, 7)                            # 任务函数参数
    }
}
```

然后启动 Celery Worker 进程：`celery worker -A celery_app --loglevel=info`，接着，启动 Celery Beat 进程，定时将任务发送到 Broker：`celery beat -A celery_app`。之后，在 Worker 窗口我们可以看到，任务 `task_add` 每 30 秒执行一次，而 `multiply_task` 每天早上 9 点 50 分执行一次。

在上面，我们用两个命令启动了 Worker 进程和 Beat 进程，我们也可以将它们放在一个命令中：

```bash
celery -B -A celery_app worker --loglevel=info
```

更多信息见官方文档。

